# seed: 42
# task_type: bert4rankloss

dataset:
  train_data_path: /workspace/ye/AI_FeedBack/data/hh_rlhf/hh_rlhf_train.jsonl
#/workspace/ye/AI_FeedBack/data/hh_rlhf/hh_rlhf_train.jsonl
# /workspace/ye/AI_FeedBack/data/hh_rlhf/hh_rlhf_test.jsonl
  val_data_path: /workspace/ye/AI_FeedBack/data/hh_rlhf/hh_rlhf_test.jsonl
  test_data_path: /workspace/ye/AI_FeedBack/data/hh_rlhf/hh_rlhf_test.jsonl
  max_seq_len: 1024
  max_prompt_length: 512
  max_response_length: 512
  datatype: 'hh-rlhf'

model:
  model_type: 'opt'
  offload: false
  model_path: /workspace/ye/DeepSpeed-Chat/training/step1_supervised_finetuning/output
#/workspace/ye/DeepSpeed-Chat/training/step1_supervised_finetuning/output
train:
  gradient_accumulation_steps: 1
  learning_rate: 5e-4
  lr_scheduler_type: cosine
  per_device_eval_batch_size: 4
  per_device_train_batch_size: 4
  num_warmup_steps: 100
  weight_decay: 0.1
  num_train_epochs: 1
  Dropout: 0.1
  save_path: /workspace/ye/DPO/checkpoint
  beta: 0.1

deepspeed:
  offload: false
  zero_stage: 2

log:
  checkpoint_save_interval: 500
  eval_epoch_ratio: 0.5
  eval_interval: 500
  project_name: 'debug_model'
  run_name: '122-lr1e5-DPO'
  output_dir: /workspace/ye/DPO/checkpoint

evaluator:
  data_path: ''
  checkpoint_path: ''
  result_save_path: ''